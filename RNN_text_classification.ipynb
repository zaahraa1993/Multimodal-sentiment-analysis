{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaahraa1993/Multimodal-sentiment-analysis/blob/main/RNN_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcty7VL1v6UV",
        "outputId": "4d81d35c-b916-4c96-e9e8-e334857a2518",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchtext==0.6)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "taX-Dr5ev-65"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator\n",
        "from torchtext.data import Example, Dataset\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "7wbWD4yyZ-ZU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yu8kH04cmdKU"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_tokenizer(text):\n",
        "    return [token.text for token in nlp(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UFb570wUmdX5"
      },
      "outputs": [],
      "source": [
        "TEXT = Field(tokenize=spacy_tokenizer, lower=True, include_lengths=True)\n",
        "LABEL = LabelField(dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved splits\n",
        "train_texts = np.load('/content/drive/MyDrive/Colab Notebooks/train_data.npy', allow_pickle=True)\n",
        "train_labels = np.load('/content/drive/MyDrive/Colab Notebooks/train_labels.npy', allow_pickle=True)\n",
        "val_texts = np.load('/content/drive/MyDrive/Colab Notebooks/val_data.npy', allow_pickle=True)\n",
        "val_labels = np.load('/content/drive/MyDrive/Colab Notebooks/val_labels.npy', allow_pickle=True)\n",
        "test_texts = np.load('/content/drive/MyDrive/Colab Notebooks/test_data.npy', allow_pickle=True)\n",
        "test_labels = np.load('/content/drive/MyDrive/Colab Notebooks/test_labels.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "7reKv_wH8Eo2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to datasets\n",
        "def create_dataset(texts, labels, fields):\n",
        "    examples = [Example.fromlist([text, label], fields) for text, label in zip(texts, labels)]\n",
        "    return Dataset(examples, fields)\n",
        "\n",
        "train_data = create_dataset(train_texts, train_labels, [('text', TEXT), ('label', LABEL)])\n",
        "valid_data = create_dataset(val_texts, val_labels, [('text', TEXT), ('label', LABEL)])\n",
        "test_data = create_dataset(test_texts, test_labels, [('text', TEXT), ('label', LABEL)])"
      ],
      "metadata": {
        "id": "vSrINey18ax3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Hvoe0rSemngh"
      },
      "outputs": [],
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kF4ZyHLOmpsY"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8FluWd23ms53"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VFOen4WTmxQY"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(hidden.squeeze(0))\n",
        "        hidden = self.fc(hidden)\n",
        "        return hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aBoYM7Tgm2zW"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xEluByf6m7o2"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "early_stopping_patience = 2\n",
        "no_improvement_epochs = 0\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PRV5UQzOnA0x"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, text_lengths = batch.text\n",
        "    predictions = model(text, text_lengths).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zQoT6UAZnHSd"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  predictions_all = []\n",
        "  labels_all = []\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      predictions = model(text, text_lengths).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = binary_accuracy(predictions, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "      predictions_all.extend(predictions.tolist())\n",
        "      labels_all.extend(batch.label.tolist())\n",
        "\n",
        "  avg_loss = epoch_loss / len(iterator)\n",
        "  avg_acc = epoch_acc / len(iterator)\n",
        "\n",
        "  return avg_loss, avg_acc, predictions_all, labels_all\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GXyb5ou0zCqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "33100839-910d-43cd-898f-55a73a1294bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.465 | Train Acc: 78.75%\n",
            "\t Val. Loss: 0.553 |  Val. Acc: 73.89%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.375 | Train Acc: 83.86%\n",
            "\t Val. Loss: 0.384 |  Val. Acc: 83.47%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.318 | Train Acc: 86.59%\n",
            "\t Val. Loss: 0.361 |  Val. Acc: 85.09%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.284 | Train Acc: 88.22%\n",
            "\t Val. Loss: 0.306 |  Val. Acc: 87.72%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.257 | Train Acc: 89.43%\n",
            "\t Val. Loss: 0.301 |  Val. Acc: 88.47%\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "N_EPOCH = 5\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc, _, _ = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        no_improvement_epochs = 0\n",
        "        torch.save(model.state_dict(), 'rnn_model.pt')\n",
        "    else:\n",
        "        no_improvement_epochs += 1\n",
        "\n",
        "    if no_improvement_epochs >= early_stopping_patience:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('rnn_model.pt'))\n",
        "\n",
        "# Evaluate on the test set\n",
        "_, _, all_rnn_predictions, all_true_labels = evaluate(model, test_iterator, criterion)"
      ],
      "metadata": {
        "id": "Oyl3RAZ8LbWf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save RNN predictions and true labels\n",
        "np.save('rnn_predictions.npy', np.array(all_rnn_predictions))\n",
        "np.save('rnn_true_labels.npy', np.array(all_true_labels))"
      ],
      "metadata": {
        "id": "1oOvO4G6LfpK"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HazH6i81VsB8VtMamF79Nl82rjNf6Ej_",
      "authorship_tag": "ABX9TyNpq43IvpcYvEJZUrLlhGGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}